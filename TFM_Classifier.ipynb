{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import pandas and scikit libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import svm, preprocessing, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, GridSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# Import libraries for time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import json\n",
    "\n",
    "## Classifier to be used with different sklearn Estimators\n",
    "## Performs LOOCV for testing, 10-fold CV for hyperparameter tuning\n",
    "## Uses ROC AUC as score metric\n",
    "def loo_cv(Estimator, parameters, filename):\n",
    "    t1=datetime.now() # Start time\n",
    "    df=pd.read_csv(\"data_preproc.csv\") # data file\n",
    "    Xr_t = df.iloc[:,1:5] # TODO: parameter for number of variables taken from file\n",
    "    yr = df['class']\n",
    "    print(Xr_t.head()) # Check file\n",
    "    # Scaler for train and test data\n",
    "    scaler = preprocessing.StandardScaler().fit(Xr_t)\n",
    "    Xr=scaler.transform(Xr_t)\n",
    "    # Leave One Out cross validation\n",
    "    loo=LeaveOneOut()\n",
    "    df_g=pd.DataFrame(loo.split(Xr,yr)) # Dataframe with train and test index for each split\n",
    "    df_g=df_g.rename({0: 'Train', 1: 'Test'}, axis='columns')\n",
    "    best_params=[] # Initialize list for best params in each split\n",
    "    y_pred=[] # Initialize list for predictions on test data \n",
    "    y_pred_prob=[] #Initialize list for predictions with probabilities on test data\n",
    "    print(\"\\n\\nLongitud del dataset: \"+str(len(df_g))) # Check the number of splits\n",
    "    for row in df_g.itertuples():\n",
    "        train_set_x=Xr[row.Train]\n",
    "        train_set_y=yr[row.Train]\n",
    "        test_set_x=Xr[row.Test]\n",
    "        test_set_y=yr[row.Test]\n",
    "        cv_model=GridSearchCV(Estimator, parameters, \n",
    "                              scoring=metrics.make_scorer(metrics.roc_auc_score),\n",
    "                              n_jobs=-1, cv=10)\n",
    "        cv_model.fit(train_set_x,train_set_y) # Fit to train data\n",
    "        param=cv_model.best_params_\n",
    "        param['score']=cv_model.best_score_\n",
    "        best_params.append(param)\n",
    "        yhat=cv_model.predict(test_set_x) # Predict on test datapoint with best params\n",
    "        y_pred.append(yhat)\n",
    "        try:\n",
    "            yhat_prob=cv_model.predict_proba(test_set_x) # Predict on test datapoint with best params\n",
    "            y_pred_prob.append(yhat_prob[0,1])\n",
    "        except AttributeError:\n",
    "            y_pred_prob.append(yhat) # Method doesn't return probabilities\n",
    "    y_pred_df=pd.DataFrame({'bin':y_pred, 'prob':y_pred_prob})\n",
    "    print(y_pred_df.head())\n",
    "    print('\\nScorer: '+str(cv_model.scorer_))\n",
    "    # Write to files\n",
    "    filename1=filename + '.json'\n",
    "    filename2=filename + '_pred.csv'\n",
    "    filename3=filename + '_info.csv'\n",
    "    y_pred_df.to_csv(filename2, index=False, header=False)\n",
    "    with open(filename1, 'w+') as outfile:\n",
    "        json.dump(best_params, outfile)\n",
    "    t2=datetime.now()\n",
    "    delta=str(t2-t1)\n",
    "    print('\\nTiempo de ejecución: ' + delta)\n",
    "    score_test=metrics.roc_auc_score(yr, y_pred_df['bin'])\n",
    "    print('\\nScore (AUC) de test binario: ', score_test)\n",
    "    score_test_prob=metrics.roc_auc_score(yr, y_pred_df['prob'])\n",
    "    print('\\nScore (AUC) de test proba: ', score_test_prob)\n",
    "    with open(filename3, 'w+') as f:\n",
    "        f.write('Tiempo de ejecución: ' + delta)\n",
    "        f.write('\\nFecha: ' + str(date.today()))\n",
    "        f.write('\\nScore (AUC) de test proba: '+ str(score_test_prob))\n",
    "        f.write('\\nScore (AUC) de test binario: '+ str(score_test))\n",
    "        f.write('\\n')\n",
    "        f.write(str(parameters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
